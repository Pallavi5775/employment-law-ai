{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clause Segmentation\n",
    "\n",
    "Segment contract text into clauses using rule-based heuristics + sentence transformers clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13562f1b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "silver_clean_path = \"abfss://silver@ragstorage4122025.dfs.core.windows.net/contracts_silver_delta/\"\n",
    "gold_path = \"abfss://gold@ragstorage4122025.dfs.core.windows.net/contracts_gold_delta/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a75ece4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pyspark.sql.functions import udf, explode, col, monotonically_increasing_id\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "\n",
    "\n",
    "df = spark.read.format(\"delta\").load(silver_clean_path)\n",
    "\n",
    "# ---------------- Clause Segmentation ----------------\n",
    "def extract_clauses(text):\n",
    "    if not text: return []\n",
    "    parts = re.split(r\"[.\\n]\", text)\n",
    "    return [p.strip() for p in parts if len(p.strip()) > 30]   # min clause length\n",
    "\n",
    "extract_clauses_udf = udf(extract_clauses, ArrayType(StringType()))\n",
    "\n",
    "df_clauses = df.withColumn(\"clause\", explode(extract_clauses_udf(col(\"text_clean\")))) \\\n",
    "               .select(\"filename\",\"clause\")\n",
    "\n",
    "# ---------------- Feature Extraction (Rule-Based) ----------------\n",
    "FEATURES = {\n",
    "    \"salary\": r\"salary|compensation|ctc|bonus|package|pay\",\n",
    "    \"notice_period\": r\"notice period|prior notice\",\n",
    "    \"termination\": r\"termination|terminate|severance|exit\",\n",
    "    \"confidentiality\": r\"confidential|non-disclosure|nda\",\n",
    "    \"ip_rights\": r\"intellectual property|IP|ownership\",\n",
    "    \"non_compete\": r\"non[- ]?compete|restrict\",\n",
    "    \"leave_policy\": r\"leave|vacation|holiday|PTO\",\n",
    "}\n",
    "\n",
    "def detect_features(text):\n",
    "    tags = []\n",
    "    for feature,pattern in FEATURES.items():\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            tags.append(feature)\n",
    "    return tags or [\"general_clause\"]\n",
    "\n",
    "feature_udf = udf(detect_features, ArrayType(StringType()))\n",
    "\n",
    "df_gold = df_clauses.withColumn(\"features\", feature_udf(col(\"clause\"))) \\\n",
    "                     .withColumn(\"id\", monotonically_increasing_id())\n",
    "\n",
    "# ---------------- Save to GOLD ----------------\n",
    "df_gold.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(gold_path)\n",
    "\n",
    "display(df_gold.limit(20))\n",
    "print(\"GOLD READY — Clauses with feature tags ✔\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
