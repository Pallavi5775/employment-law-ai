{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clause Segmentation\n",
    "\n",
    "Segment contract text into clauses using rule-based heuristics + sentence transformers clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1048dd2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "%pip install transformers torch sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13562f1b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "def segment_clauses(text):\n",
    "    parts = [p.strip() for p in text.split(\"\\n\") if len(p.strip()) > 20]\n",
    "    return parts\n",
    "\n",
    "def embed_clauses(parts):\n",
    "    return model.encode(parts, convert_to_numpy=True).tolist()\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "segment_udf = udf(segment_clauses, ArrayType(StringType()))\n",
    "silver_path = \"abfss://silver@ragstorage4122025.dfs.core.windows.net\"\n",
    "silver_df = (\n",
    "    spark.read\n",
    "    .format(\"delta\")\n",
    "    .load(silver_path)\n",
    ")\n",
    "\n",
    "gold_df = silver_df.withColumn(\"clauses\", segment_udf(col(\"text_clean\")))\n",
    "gold_path = \"abfss://gold@ragstorage4122025.dfs.core.windows.net\"\n",
    "\n",
    "gold_df.write.format(\"delta\").mode(\"overwrite\").save(gold_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
