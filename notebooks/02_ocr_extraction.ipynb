{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Extraction\n",
    "\n",
    "Use Azure Form Recognizer or Tika/pdfplumber to extract text from scanned PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c25e127",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "bronze_df = spark.read.format(\"delta\").load(bronze_path)\n",
    "\n",
    "def extract_text(bytes_data, filename):\n",
    "    try:\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            with pdfplumber.open(io.BytesIO(bytes_data)) as pdf:\n",
    "                return \"\\n\".join([page.extract_text() or \"\" for page in pdf.pages])\n",
    "        elif filename.lower().endswith(\".txt\"):\n",
    "            return bytes_data.decode(\"utf-8\", errors=\"ignore\")\n",
    "        elif filename.lower().endswith(\".docx\"):\n",
    "            import docx\n",
    "            import io\n",
    "            document = docx.Document(io.BytesIO(bytes_data))\n",
    "            return \"\\n\".join([p.text for p in document.paragraphs])\n",
    "        else:\n",
    "            return \"\"\n",
    "    except Exception as e:\n",
    "        return \"\"\n",
    "\n",
    "extract_text_udf = udf(extract_text, StringType())\n",
    "\n",
    "silver_df = bronze_df.withColumn(\"text_raw\", extract_text_udf(col(\"content\"), col(\"filename\")))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
